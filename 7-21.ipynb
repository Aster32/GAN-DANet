{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from model import OriginalRelationshipLearner, Discriminator1, FlexibleUpsamplingModule, weights_init_normal, SSIM, TVLoss, PerceptualLoss\n",
    "from datasets import CustomDataset, load_data\n",
    "import torch.nn.functional as F\n",
    "from utils import plot_results\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from taylorDiagram import TaylorDiagram\n",
    "from torchvision import models\n",
    "def visualize_model(model, filename,x):\n",
    "    #x = torch.randn(input_size)\n",
    "    y = model(x)\n",
    "    dot = make_dot(y, params=dict(model.named_parameters()), show_attrs=True, show_saved=True)\n",
    "    dot.format = 'png'\n",
    "    dot.render(filename, cleanup=True)\n",
    "    print(f\"Model architecture saved as '{filename}.png'\")\n",
    "class ModelTrainer:\n",
    "    def __init__(self, epochs, batch_size, relationship_learner, relationship_output_channels, smoothing_method=None, attention=None, senet=None, rand=42):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        #self.relationship_learner = relationship_learner\n",
    "        self.relationship_output_channels = relationship_output_channels\n",
    "        self.smoothing_method = smoothing_method\n",
    "        self.attention = attention\n",
    "        self.senet = senet\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.rand=rand\n",
    "        # Load and prepare data\n",
    "        [self.lr_grace_05,self.trend05], [self.lr_grace_025,self.trend25], self.hr_aux, self.grace_scaler_05, self.grace_scaler_025, self.aux_scalers = load_data()\n",
    "        \n",
    "        # Apply data smoothing to hr_aux if smoothing_method is specified\n",
    "        if self.smoothing_method:\n",
    "            self.hr_aux = self.smoothing_method(self.hr_aux)\n",
    "        else:\n",
    "            self.hr_aux = self.hr_aux\n",
    "        \n",
    "        # Split data into training and testing sets\n",
    "        self.train_lr_grace_05, self.test_lr_grace_05, self.train_lr_grace_025, self.test_lr_grace_025, self.train_hr_aux, self.test_hr_aux = train_test_split(\n",
    "            self.lr_grace_05, self.lr_grace_025, self.hr_aux, test_size=0.2, random_state=self.rand)\n",
    "        \n",
    "        # Create datasets and dataloaders\n",
    "        self.train_dataset = CustomDataset(self.train_lr_grace_05, self.train_lr_grace_025, self.train_hr_aux)\n",
    "        self.test_dataset = CustomDataset(self.test_lr_grace_05, self.test_lr_grace_025, self.test_hr_aux)\n",
    "        \n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "        \n",
    "        # Initialize models\n",
    "        #self.relationship_learner = self.relationship_learner.to(self.device)\n",
    "        self.discriminator = Discriminator1().to(self.device)\n",
    "        self.upsampling_module = FlexibleUpsamplingModule(input_channels=self.hr_aux.shape[-1]+1,attention_type=self.attention).to(self.device)\n",
    "        \n",
    "        self.flag=self.attention\n",
    "        self.attention=None\n",
    "        # Initialize optional modules\n",
    "        if self.attention:\n",
    "            self.attention_module = self.attention.to(self.device)\n",
    "        else:\n",
    "            self.attention_module = None\n",
    "            \n",
    "        if self.senet:\n",
    "            self.senet_module = self.senet.to(self.device)\n",
    "        else:\n",
    "            self.senet_module = None\n",
    "        \n",
    "        # Initialize weights\n",
    "        #self.relationship_learner.apply(weights_init_normal)\n",
    "        self.discriminator.apply(weights_init_normal)\n",
    "        self.upsampling_module.apply(weights_init_normal)\n",
    "        if self.attention_module:\n",
    "            self.attention_module.apply(weights_init_normal)\n",
    "        if self.senet_module:\n",
    "            self.senet_module.apply(weights_init_normal)\n",
    "        \n",
    "        # Optimizers\n",
    "        #self.optimizer_RL = optim.Adam(self.relationship_learner.parameters(), lr=0.0002)\n",
    "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
    "        self.optimizer_U = optim.Adam(self.upsampling_module.parameters(), lr=0.0002)\n",
    "        if self.attention_module:\n",
    "            self.optimizer_A = optim.Adam(self.attention_module.parameters(), lr=0.0002)\n",
    "        if self.senet_module:\n",
    "            self.optimizer_SE = optim.Adam(self.senet_module.parameters(), lr=0.0002)\n",
    "        \n",
    "        # Learning Rate Schedulers\n",
    "        #self.scheduler_RL = ReduceLROnPlateau(self.optimizer_RL, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        self.scheduler_D = ReduceLROnPlateau(self.optimizer_D, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        self.scheduler_U = ReduceLROnPlateau(self.optimizer_U, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        if self.attention_module:\n",
    "            self.scheduler_A = ReduceLROnPlateau(self.optimizer_A, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        if self.senet_module:\n",
    "            self.scheduler_SE = ReduceLROnPlateau(self.optimizer_SE, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        \n",
    "        # Loss functions\n",
    "        self.adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.pixelwise_loss = torch.nn.MSELoss()\n",
    "        self.ssim_loss = SSIM(window_size=11, size_average=True).to(self.device)\n",
    "        self.tv_loss = TVLoss(weight=1e-5).to(self.device)\n",
    "        self.perceptual_loss = PerceptualLoss(use_gpu=torch.cuda.is_available())\n",
    "        #self.perceptual_loss = PerceptualLoss([1, 6, 11, 20], use_gpu=torch.cuda.is_available())\n",
    "    def smooth_data_gaussian(self, data, sigma=2):\n",
    "        return gaussian_filter(data, sigma=sigma)\n",
    "\n",
    "    def smooth_data_median(self, data, size=3):\n",
    "        return median_filter(data, size=size)\n",
    "\n",
    "    def smooth_data_savitzky_golay(self, data, window_length=5, polyorder=2):\n",
    "        return savgol_filter(data, window_length, polyorder)\n",
    "\n",
    "    def train(self):\n",
    "        train_losses_G = []\n",
    "        train_losses_D = []\n",
    "        i=0\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss_G = 0\n",
    "            epoch_loss_D = 0\n",
    "            #self.relationship_learner.train()\n",
    "            for lr_grace_05, lr_grace_025, hr_aux in self.train_loader:\n",
    "                lr_grace = F.interpolate(lr_grace_05, scale_factor=0.5, mode='bicubic', align_corners=False)\n",
    "                lr_grace, hr_aux = lr_grace.to(self.device), hr_aux.to(self.device)\n",
    "                lr_grace_025 = lr_grace_025.to(self.device)\n",
    "                \n",
    "                # Combine lr_grace and downsampled hr_aux\n",
    "                downsampled_aux = F.interpolate(hr_aux, scale_factor=0.25, mode='bicubic', align_corners=False)\n",
    "                combined_input = torch.cat([lr_grace, downsampled_aux], dim=1)\n",
    "                # Learn relationship features\n",
    "                #relationship_features = self.relationship_learner(combined_input)\n",
    "                relationship_features = combined_input\n",
    "                # Apply attention or SENet if exists\n",
    "                if self.attention_module:\n",
    "                    relationship_features = self.attention_module(relationship_features)\n",
    "                elif self.senet_module:\n",
    "                    relationship_features = self.senet_module(relationship_features)\n",
    "\n",
    "                # Generate HR result using improved upsampling module\n",
    "                hr_generated = self.upsampling_module(relationship_features)\n",
    "                #generator_input_size=(1,self.hr_aux.shape[-1]+1,180,88)\n",
    "                # Discriminator training\n",
    "                self.optimizer_D.zero_grad()\n",
    "                real_output = self.discriminator(lr_grace_025)\n",
    "                fake_output = self.discriminator(hr_generated.detach())\n",
    "                real_labels = torch.ones_like(real_output, device=self.device)\n",
    "                fake_labels = torch.zeros_like(fake_output, device=self.device)\n",
    "\n",
    "                loss_D_real = self.adversarial_loss(real_output, real_labels)\n",
    "                loss_D_fake = self.adversarial_loss(fake_output, fake_labels)\n",
    "                loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "                loss_D.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                # Generator training (RelationshipLearner and ImprovedUpsamplingModule)\n",
    "                #self.optimizer_RL.zero_grad()\n",
    "                self.optimizer_U.zero_grad()\n",
    "                fake_output = self.discriminator(hr_generated)\n",
    "                loss_G_adv = self.adversarial_loss(fake_output, real_labels)\n",
    "                loss_G_pixel = self.pixelwise_loss(hr_generated, lr_grace_025)\n",
    "                loss_G_ssim = 1 - self.ssim_loss(hr_generated, lr_grace_025)\n",
    "                loss_G_tv = self.tv_loss(hr_generated)\n",
    "                loss_G_perceptual = self.perceptual_loss(hr_generated, lr_grace_025)\n",
    "                loss_G = loss_G_adv + loss_G_pixel+loss_G_perceptual + loss_G_tv#+ loss_G_pixel#+ loss_G_ssim # + loss_G_pixel # #+ loss_G_tv+ loss_G_ssim\n",
    "                loss_G.backward()\n",
    "                #self.optimizer_RL.step()\n",
    "                self.optimizer_U.step()\n",
    "\n",
    "                epoch_loss_G += loss_G.item()\n",
    "                epoch_loss_D += loss_D.item()\n",
    "\n",
    "            # Update the schedulers at the end of the epoch\n",
    "            #self.scheduler_RL.step(epoch_loss_G)\n",
    "            self.scheduler_D.step(epoch_loss_D)\n",
    "            self.scheduler_U.step(epoch_loss_G)\n",
    "            if self.attention_module:\n",
    "                self.scheduler_A.step(epoch_loss_G)\n",
    "            if self.senet_module:\n",
    "                self.scheduler_SE.step(epoch_loss_G)\n",
    "\n",
    "            train_losses_G.append(epoch_loss_G / len(self.train_loader))\n",
    "            train_losses_D.append(epoch_loss_D / len(self.train_loader))\n",
    "\n",
    "            #print(f'Epoch [{epoch+1}/{self.epochs}], Loss D: {epoch_loss_D/len(self.train_loader):.4f}, Loss G: {epoch_loss_G/len(self.train_loader):.4f}')\n",
    "\n",
    "        return train_losses_G, train_losses_D\n",
    "\n",
    "    def evaluate(self):\n",
    "       # self.relationship_learner.eval()\n",
    "        self.upsampling_module.eval()\n",
    "        if self.attention_module:\n",
    "            self.attention_module.eval()\n",
    "        if self.senet_module:\n",
    "            self.senet_module.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            trues = []\n",
    "            bs=0\n",
    "            for lr_grace_05, lr_grace_025, hr_aux in self.test_loader:\n",
    "                \n",
    "                bs=bs+1\n",
    "                if bs==-1 :\n",
    "                    lr_grace_05, lr_grace_025, hr_aux = lr_grace_05.to(self.device), lr_grace_025.to(self.device), hr_aux.to(self.device)\n",
    "                    \n",
    "                    # Combine lr_grace and downsampled hr_aux\n",
    "                    combined_input = torch.cat([lr_grace_025, hr_aux], dim=1)\n",
    "\n",
    "                    # Learn relationship features\n",
    "                    #relationship_features = self.relationship_learner(combined_input)\n",
    "                    relationship_features = combined_input\n",
    "                    # Apply attention or SENet if exists\n",
    "                    if self.attention_module:\n",
    "                        relationship_features = self.attention_module(relationship_features)\n",
    "                    elif self.senet_module:\n",
    "                        relationship_features = self.senet_module(relationship_features)\n",
    "\n",
    "                    # Generate HR result using improved upsampling module\n",
    "                    hr_generated = self.upsampling_module(relationship_features)\n",
    "\n",
    "                    plot_results(lr_grace_05[0,0].cpu(), hr_generated[0,0].cpu(), lr_grace_025[0,0].cpu(), True)\n",
    "                # Save predictions and true values for metrics calculation\n",
    "                lr_grace_05, lr_grace_025, hr_aux = lr_grace_05.to(self.device), lr_grace_025.to(self.device), hr_aux.to(self.device)\n",
    "                lr_grace = F.interpolate(lr_grace_05, scale_factor=0.5, mode='bicubic', align_corners=False)\n",
    "                \n",
    "                # Combine lr_grace and downsampled hr_aux\n",
    "                downsampled_aux = F.interpolate(hr_aux, scale_factor=0.25, mode='bicubic', align_corners=False)\n",
    "                combined_input = torch.cat([lr_grace, downsampled_aux], dim=1)\n",
    "\n",
    "                # Learn relationship features\n",
    "                #relationship_features = self.relationship_learner(combined_input)\n",
    "                relationship_features = combined_input\n",
    "                # Apply attention or SENet if exists\n",
    "                if self.attention_module:\n",
    "                    relationship_features = self.attention_module(relationship_features)\n",
    "                elif self.senet_module:\n",
    "                    relationship_features = self.senet_module(relationship_features)\n",
    "\n",
    "                # Generate HR result using improved upsampling module\n",
    "                hr_generated = self.upsampling_module(relationship_features)\n",
    "\n",
    "                # Upsample lr_grace to create the ground truth for hr_generated\n",
    "                hr_grace_upsampled = lr_grace_025\n",
    "                preds.append(hr_generated.cpu().numpy())\n",
    "                trues.append(hr_grace_upsampled.cpu().numpy())\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            preds = np.concatenate(preds, axis=0).reshape(-1)\n",
    "            trues = np.concatenate(trues, axis=0).reshape(-1)\n",
    "\n",
    "            cc=np.corrcoef(trues, preds)\n",
    "            mse = mean_squared_error(trues, preds)\n",
    "            mae = mean_absolute_error(trues, preds)\n",
    "            r2 = r2_score(trues, preds)\n",
    "\n",
    "            print(f\"Test MSE: {mse}, Test MAE: {mae}, Test R²: {r2}, Test cc: {cc}\")\n",
    "\n",
    "        return preds, trues, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 40, 64, 128])\n",
      "Output shape: torch.Size([1, 1, 256, 512])\n",
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.11383958160877228, Test MAE: 0.20022013783454895, Test R²: 0.7830340436909888, Test cc: [[1.         0.88691439]\n",
      " [0.88691439 1.        ]]\n",
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.10292913764715195, Test MAE: 0.1883358657360077, Test R²: 0.803828184313513, Test cc: [[1.         0.90110224]\n",
      " [0.90110224 1.        ]]\n",
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.0857921689748764, Test MAE: 0.17638634145259857, Test R²: 0.8316890645125323, Test cc: [[1.         0.91644609]\n",
      " [0.91644609 1.        ]]\n",
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.10059121996164322, Test MAE: 0.18262481689453125, Test R²: 0.8232363518544801, Test cc: [[1.         0.91184227]\n",
      " [0.91184227 1.        ]]\n",
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.09452688694000244, Test MAE: 0.18308766186237335, Test R²: 0.8352480262732265, Test cc: [[1.         0.91821564]\n",
      " [0.91821564 1.        ]]\n",
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sun/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.09696660190820694, Test MAE: 0.1813029944896698, Test R²: 0.8080979518827197, Test cc: [[1.        0.9055501]\n",
      " [0.9055501 1.       ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Plot training losses for each model\\nplt.figure(figsize=(12, 6))\\nplt.plot(train_losses_G1, label=\\'Generator Loss - Baseline\\')\\nplt.plot(train_losses_D1, label=\\'Discriminator Loss - Baseline\\')\\nplt.plot(train_losses_G2, label=\\'Generator Loss - With SEnet\\')\\nplt.plot(train_losses_D2, label=\\'Discriminator Loss - With SEnet\\')\\nplt.plot(train_losses_G3, label=\\'Generator Loss - With None\\')\\nplt.plot(train_losses_D3, label=\\'Discriminator Loss - With None\\')\\nplt.xlabel(\\'Epoch\\')\\nplt.ylabel(\\'Loss\\')\\nplt.legend()\\nplt.title(\\'Training Losses\\')\\nplt.show()\\n\\n# Prepare data for Taylor diagram\\nref = pd.Series(trues1, name=\\'Reference\\')\\nsamples = pd.DataFrame({\\n    \\'Baseline\\': preds1,\\n    \\'With SEnet\\': preds2,\\n    \\'With Simple\\': preds3,\\n    \\'With CBAM\\': preds4,\\n    \\'With nonlocal\\': preds5,\\n    \\'With selfattention\\': preds6,\\n})\\n\\n# Compute standard deviations and correlations\\nstddev = samples.std(axis=0)\\ncorrcoef = samples.corrwith(ref)\\n\\n# Create Taylor diagram for evaluation\\nfig = plt.figure(figsize=(10, 10))\\ndia = TaylorDiagram(ref.std(), fig=fig, rect=111, label=\"Reference\")\\n\\ncolors = plt.matplotlib.cm.jet(np.linspace(0, 1, len(samples.columns)))\\n\\n# Add models to Taylor diagram\\nfor i, (stddev, corrcoef) in enumerate(zip(stddev.values, corrcoef.values)):\\n    dia.add_sample(stddev, corrcoef,\\n                   marker=\\'o\\', ms=10, ls=\\'\\',\\n                   mfc=colors[i], mec=colors[i],\\n                   label=samples.columns[i])\\n\\n# Add grid and contours\\ndia.add_grid()\\ncontours = dia.add_contours(levels=5, colors=\\'0.5\\')\\nplt.clabel(contours, inline=1, fontsize=10, fmt=\\'%.2f\\')\\n\\n# Add legend\\nfig.legend(dia.samplePoints,\\n           [p.get_label() for p in dia.samplePoints],\\n           numpoints=1, prop=dict(size=\\'small\\'), loc=\\'upper right\\')\\nfig.suptitle(\"Taylor Diagram\", size=\\'x-large\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters\n",
    "epochs = 150\n",
    "batch_size = 12\n",
    "# Instantiate the module\n",
    "model = FlexibleUpsamplingModule(input_channels=40, attention_type='danet')\n",
    "\n",
    "# Move model to appropriate device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Create a dummy input tensor with non-square dimensions\n",
    "input_tensor = torch.randn(1, 40, 64, 128).to(device)  # Batch size of 1, 40 channels, 64x128 image\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Output shape\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")  # Should be (1, 1, upscaled_height, upscaled_width)\n",
    "\n",
    "\n",
    "# Define smoothing method\n",
    "smoothing_method = ModelTrainer(epochs, batch_size, OriginalRelationshipLearner(40), 1024).smooth_data_gaussian\n",
    "smoothing_method = None\n",
    "# Define modules\n",
    "#attention_module = AttentionModule(input_channels=40, output_channels=40)\n",
    "#senet_module = SqueezeExcitation(input_channels=40, reduction_ratio=8)\n",
    "\n",
    "# Train the baseline model without any additional module\n",
    "model1 = ModelTrainer(epochs=30, batch_size=batch_size, relationship_learner=OriginalRelationshipLearner(40), relationship_output_channels=1024, smoothing_method=smoothing_method)\n",
    "train_losses_G1, train_losses_D1 = model1.train()\n",
    "preds1, trues1, r2_1 = model1.evaluate()\n",
    "# Release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model with Attention\n",
    "model2 = ModelTrainer(epochs=epochs, batch_size=batch_size, relationship_learner=OriginalRelationshipLearner(40), relationship_output_channels=1024, smoothing_method=smoothing_method, attention='senet')\n",
    "train_losses_G2, train_losses_D2 = model2.train()\n",
    "preds2, trues2, r2_2 = model2.evaluate()\n",
    "# Release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model with SEnet\n",
    "model3 = ModelTrainer(epochs=epochs, batch_size=batch_size, relationship_learner=OriginalRelationshipLearner(40), relationship_output_channels=1024, smoothing_method=smoothing_method, attention='simple',rand=35)\n",
    "train_losses_G3, train_losses_D3 = model3.train()\n",
    "preds3, trues3, r2_3 = model3.evaluate()\n",
    "# Release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "model4 = ModelTrainer(epochs=epochs, batch_size=batch_size, relationship_learner=OriginalRelationshipLearner(40), relationship_output_channels=1024, smoothing_method=smoothing_method, attention='cbam',rand=31)\n",
    "train_losses_G4, train_losses_D4 = model4.train()\n",
    "preds4, trues4, r2_4 = model4.evaluate()\n",
    "torch.cuda.empty_cache()\n",
    "model5 = ModelTrainer(epochs=epochs, batch_size=batch_size, relationship_learner=OriginalRelationshipLearner(40), relationship_output_channels=1024, smoothing_method=smoothing_method, attention='nonlocal',rand=26)\n",
    "train_losses_G5, train_losses_D5 = model5.train()\n",
    "preds5, trues5, r2_5 = model5.evaluate()\n",
    "torch.cuda.empty_cache()\n",
    "model6 = ModelTrainer(epochs=epochs, batch_size=batch_size, relationship_learner=OriginalRelationshipLearner(40), relationship_output_channels=1024, smoothing_method=smoothing_method, attention='selfattention', rand=75)\n",
    "train_losses_G6, train_losses_D6 = model6.train()\n",
    "preds6, trues6, r2_6 = model6.evaluate()\n",
    "torch.cuda.empty_cache()\n",
    "'''\n",
    "# Plot training losses for each model\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses_G1, label='Generator Loss - Baseline')\n",
    "plt.plot(train_losses_D1, label='Discriminator Loss - Baseline')\n",
    "plt.plot(train_losses_G2, label='Generator Loss - With SEnet')\n",
    "plt.plot(train_losses_D2, label='Discriminator Loss - With SEnet')\n",
    "plt.plot(train_losses_G3, label='Generator Loss - With None')\n",
    "plt.plot(train_losses_D3, label='Discriminator Loss - With None')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Losses')\n",
    "plt.show()\n",
    "\n",
    "# Prepare data for Taylor diagram\n",
    "ref = pd.Series(trues1, name='Reference')\n",
    "samples = pd.DataFrame({\n",
    "    'Baseline': preds1,\n",
    "    'With SEnet': preds2,\n",
    "    'With Simple': preds3,\n",
    "    'With CBAM': preds4,\n",
    "    'With nonlocal': preds5,\n",
    "    'With selfattention': preds6,\n",
    "})\n",
    "\n",
    "# Compute standard deviations and correlations\n",
    "stddev = samples.std(axis=0)\n",
    "corrcoef = samples.corrwith(ref)\n",
    "\n",
    "# Create Taylor diagram for evaluation\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "dia = TaylorDiagram(ref.std(), fig=fig, rect=111, label=\"Reference\")\n",
    "\n",
    "colors = plt.matplotlib.cm.jet(np.linspace(0, 1, len(samples.columns)))\n",
    "\n",
    "# Add models to Taylor diagram\n",
    "for i, (stddev, corrcoef) in enumerate(zip(stddev.values, corrcoef.values)):\n",
    "    dia.add_sample(stddev, corrcoef,\n",
    "                   marker='o', ms=10, ls='',\n",
    "                   mfc=colors[i], mec=colors[i],\n",
    "                   label=samples.columns[i])\n",
    "\n",
    "# Add grid and contours\n",
    "dia.add_grid()\n",
    "contours = dia.add_contours(levels=5, colors='0.5')\n",
    "plt.clabel(contours, inline=1, fontsize=10, fmt='%.2f')\n",
    "\n",
    "# Add legend\n",
    "fig.legend(dia.samplePoints,\n",
    "           [p.get_label() for p in dia.samplePoints],\n",
    "           numpoints=1, prop=dict(size='small'), loc='upper right')\n",
    "fig.suptitle(\"Taylor Diagram\", size='x-large')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model1.upsampling_module.state_dict(), 'model1_upsampling_module.pth')\n",
    "torch.save(model2.upsampling_module.state_dict(), 'model2_upsampling_module.pth')\n",
    "torch.save(model3.upsampling_module.state_dict(), 'model3_upsampling_module.pth')\n",
    "torch.save(model4.upsampling_module.state_dict(), 'model4_upsampling_module.pth')\n",
    "torch.save(model5.upsampling_module.state_dict(), 'model5_upsampling_module.pth')\n",
    "torch.save(model6.upsampling_module.state_dict(), 'model6_upsampling_module.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
