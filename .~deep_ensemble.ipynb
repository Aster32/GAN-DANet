{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 90, 44)\n",
      "(181, 180, 88, 1)\n",
      "[509.70157107]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "[-32767.]\n",
      "Combined HR Aux Data Shape: (181, 180, 88, 45)\n",
      "0.0\n",
      "65.5\n",
      "Sliced HR Aux Data Shape: (181, 180, 88, 45)\n",
      "-5.350948318234112\n",
      "(180, 88, 7)\n",
      "最大误差: 8.881784197001252e-16\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchviz import make_dot\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from model import OriginalRelationshipLearner, Discriminator1, FlexibleUpsamplingModule, weights_init_normal, SSIM, TVLoss, PerceptualLoss\n",
    "from datasets import CustomDataset, load_data_with_augmentation, load_data\n",
    "from utils import plot_results\n",
    "from taylorDiagram import TaylorDiagram\n",
    "\n",
    "# Define the ModelTrainer class as provided\n",
    "class ModelTrainer:\n",
    "    def __init__(self, epochs, batch_size, relationship_learner, relationship_output_channels, smoothing_method=None, attention=None, senet=None, rand=42):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.relationship_output_channels = relationship_output_channels\n",
    "        self.smoothing_method = smoothing_method\n",
    "        self.attention = attention\n",
    "        self.senet = senet\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.rand = rand\n",
    "        \n",
    "        # Load and prepare data\n",
    "        [self.lr_grace_05, self.trend05], [self.lr_grace_025, self.trend25], self.hr_aux, self.grace_scaler_05, self.grace_scaler_025, self.aux_scalers = load_data_with_augmentation()\n",
    "        [self.lr_grace_05o, self.trend05o], [self.lr_grace_025o, self.trend25o], self.hr_auxo, self.grace_scaler_05o, self.grace_scaler_025o, self.aux_scalerso = load_data()\n",
    "        \n",
    "        # Apply data smoothing to hr_aux if smoothing_method is specified\n",
    "        if self.smoothing_method:\n",
    "            self.hr_aux = self.smoothing_method(self.hr_aux)\n",
    "        \n",
    "        # Split data into training and testing sets (if needed)\n",
    "        split_index = int(len(self.lr_grace_05) * 0.8)  # 80% training, 20% testing\n",
    "        self.train_lr_grace_05, self.test_lr_grace_05 = self.lr_grace_05[:split_index], self.lr_grace_05[split_index:]\n",
    "        self.train_lr_grace_025, self.test_lr_grace_025 = self.lr_grace_025[:split_index], self.lr_grace_025[split_index:]\n",
    "        self.train_hr_aux, self.test_hr_aux = self.hr_aux[:split_index], self.hr_aux[split_index:]\n",
    "        \n",
    "        # Train-test split (Optional, if you need separate splits)\n",
    "        self.train_lr_grace_05, self.test_lr_grace_05, self.train_lr_grace_025, self.test_lr_grace_025, self.train_hr_aux, self.test_hr_aux = train_test_split(\n",
    "            self.lr_grace_05, self.lr_grace_025, self.hr_aux, test_size=0.2, random_state=self.rand)\n",
    "        \n",
    "        # Create datasets and dataloaders\n",
    "        self.train_dataset = CustomDataset(self.train_lr_grace_05, self.train_lr_grace_025, self.train_hr_aux)\n",
    "        self.test_dataset = CustomDataset(self.test_lr_grace_05, self.test_lr_grace_025, self.test_hr_aux)\n",
    "        \n",
    "        # Create full dataset (no split)\n",
    "        self.full_dataset = CustomDataset(self.lr_grace_05o, self.lr_grace_025o, self.hr_auxo)\n",
    "        \n",
    "        # Dataloaders\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        # Full loader for the entire dataset (no split)\n",
    "        self.full_loader = DataLoader(self.full_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize models\n",
    "        self.discriminator = Discriminator1().to(self.device)\n",
    "        self.upsampling_module = FlexibleUpsamplingModule(input_channels=self.hr_aux.shape[-1]+1, attention_type=self.attention).to(self.device)\n",
    "        \n",
    "        # Initialize optional modules\n",
    "        if self.attention:\n",
    "            self.attention_module = self.attention.to(self.device)\n",
    "        else:\n",
    "            self.attention_module = None\n",
    "            \n",
    "        if self.senet:\n",
    "            self.senet_module = self.senet.to(self.device)\n",
    "        else:\n",
    "            self.senet_module = None\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.discriminator.apply(weights_init_normal)\n",
    "        self.upsampling_module.apply(weights_init_normal)\n",
    "        if self.attention_module:\n",
    "            self.attention_module.apply(weights_init_normal)\n",
    "        if self.senet_module:\n",
    "            self.senet_module.apply(weights_init_normal)\n",
    "        \n",
    "        # Optimizers\n",
    "        hat_parameters = list(self.upsampling_module.parameters())\n",
    "        if self.attention_module:\n",
    "            hat_parameters += list(self.attention_module.parameters())\n",
    "        if self.senet_module:\n",
    "            hat_parameters += list(self.senet_module.parameters())\n",
    "        \n",
    "        self.optimizer_D = optim.AdamW(self.discriminator.parameters(), lr=0.0004, betas=(0.5, 0.999), weight_decay=1e-4)\n",
    "        self.optimizer_U = optim.AdamW(hat_parameters, lr=0.0002, betas=(0.5, 0.999), weight_decay=1e-4)\n",
    "        \n",
    "        # Learning Rate Schedulers\n",
    "        self.scheduler_D = CosineAnnealingWarmRestarts(self.optimizer_D, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "        self.scheduler_U = CosineAnnealingWarmRestarts(self.optimizer_U, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "        \n",
    "        # Loss functions\n",
    "        self.adversarial_loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.pixelwise_loss = torch.nn.MSELoss()\n",
    "        self.ssim_loss = SSIM(window_size=11, size_average=True).to(self.device)\n",
    "        self.tv_loss = TVLoss(weight=1e-5).to(self.device)\n",
    "        self.perceptual_loss = PerceptualLoss(use_gpu=torch.cuda.is_available())\n",
    "\n",
    "    \n",
    "    def smooth_data_gaussian(self, data, sigma=2):\n",
    "        return gaussian_filter(data, sigma=sigma)\n",
    "\n",
    "    def smooth_data_median(self, data, size=3):\n",
    "        return median_filter(data, size=size)\n",
    "\n",
    "    def smooth_data_savitzky_golay(self, data, window_length=5, polyorder=2):\n",
    "        return savgol_filter(data, window_length, polyorder)\n",
    "\n",
    "    def train(self):\n",
    "        train_losses_G = []\n",
    "        train_losses_D = []\n",
    "        patience = 20  # Early stopping patience\n",
    "        min_delta = 0  # Minimum change in monitored value to qualify as improvement\n",
    "        trigger_times = 0  # Counter for early stopping\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss_G = 0\n",
    "            epoch_loss_D = 0\n",
    "\n",
    "            # Training phase\n",
    "            self.upsampling_module.train()\n",
    "            self.discriminator.train()\n",
    "            if self.attention_module:\n",
    "                self.attention_module.train()\n",
    "            if self.senet_module:\n",
    "                self.senet_module.train()\n",
    "\n",
    "            for lr_grace_05, lr_grace_025, hr_aux in self.train_loader:\n",
    "                lr_grace = F.interpolate(lr_grace_05, scale_factor=0.5, mode='bicubic', align_corners=False)\n",
    "                lr_grace, hr_aux = lr_grace.to(self.device), hr_aux.to(self.device)\n",
    "                lr_grace_025 = lr_grace_025.to(self.device)\n",
    "\n",
    "                # Combine lr_grace and downsampled hr_aux\n",
    "                downsampled_aux = F.interpolate(hr_aux, scale_factor=0.25, mode='bicubic', align_corners=False)\n",
    "                combined_input = torch.cat([lr_grace, downsampled_aux], dim=1)\n",
    "\n",
    "                # Learn relationship features\n",
    "                relationship_features = combined_input\n",
    "                if self.attention_module:\n",
    "                    relationship_features = self.attention_module(relationship_features)\n",
    "                elif self.senet_module:\n",
    "                    relationship_features = self.senet_module(relationship_features)\n",
    "\n",
    "                # Generate HR result using HAT module\n",
    "                hr_generated = self.upsampling_module(relationship_features)\n",
    "\n",
    "                # Discriminator training\n",
    "                self.optimizer_D.zero_grad()\n",
    "                real_output = self.discriminator(lr_grace_025)\n",
    "                fake_output = self.discriminator(hr_generated.detach())\n",
    "                real_labels = torch.ones_like(real_output, device=self.device)\n",
    "                fake_labels = torch.zeros_like(fake_output, device=self.device)\n",
    "\n",
    "                loss_D_real = self.adversarial_loss(real_output, real_labels)\n",
    "                loss_D_fake = self.adversarial_loss(fake_output, fake_labels)\n",
    "                loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "                loss_D.backward()\n",
    "                self.optimizer_D.step()\n",
    "\n",
    "                # Generator training\n",
    "                self.optimizer_U.zero_grad()\n",
    "                fake_output = self.discriminator(hr_generated)\n",
    "                loss_G_adv = self.adversarial_loss(fake_output, real_labels)\n",
    "                loss_G_pixel = self.pixelwise_loss(hr_generated, lr_grace_025)\n",
    "                loss_G_ssim = 1 - self.ssim_loss(hr_generated, lr_grace_025)\n",
    "                loss_G_tv = self.tv_loss(hr_generated)\n",
    "                loss_G_perceptual = self.perceptual_loss(hr_generated, lr_grace_025)\n",
    "                loss_weight = epoch / self.epochs  # Linearly increase adversarial weight HAT\n",
    "                loss_G = (1 - loss_weight) * loss_G_pixel + loss_weight * loss_G_adv + loss_G_tv + loss_G_perceptual\n",
    "                loss_G.backward()\n",
    "                self.optimizer_U.step()\n",
    "\n",
    "                epoch_loss_G += loss_G.item()\n",
    "                epoch_loss_D += loss_D.item()\n",
    "\n",
    "            # Average losses over the epoch\n",
    "            avg_epoch_loss_G = epoch_loss_G / len(self.train_loader)\n",
    "            avg_epoch_loss_D = epoch_loss_D / len(self.train_loader)\n",
    "\n",
    "            # Early Stopping Check\n",
    "            if avg_epoch_loss_G < best_loss - min_delta:\n",
    "                best_loss = avg_epoch_loss_G\n",
    "                trigger_times = 0\n",
    "                # Save the best model state\n",
    "                torch.save(self.upsampling_module.state_dict(), 'best_model.pth')\n",
    "            else:\n",
    "                trigger_times += 1\n",
    "                print(f'EarlyStopping: {trigger_times}/{patience} epochs with no improvement.')\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping triggered.')\n",
    "                    # Load the best model state before stopping\n",
    "                    self.upsampling_module.load_state_dict(torch.load('best_model.pth'))\n",
    "                    return train_losses_G, train_losses_D\n",
    "\n",
    "            # Update the schedulers at the end of the epoch\n",
    "            self.scheduler_D.step()\n",
    "            self.scheduler_U.step()\n",
    "\n",
    "            train_losses_G.append(avg_epoch_loss_G)\n",
    "            train_losses_D.append(avg_epoch_loss_D)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{self.epochs}], Loss D: {avg_epoch_loss_D:.4f}, Loss G: {avg_epoch_loss_G:.4f}')\n",
    "\n",
    "        # Load the best model at the end of training\n",
    "        self.upsampling_module.load_state_dict(torch.load('best_model.pth'))\n",
    "        return train_losses_G, train_losses_D\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.upsampling_module.eval()\n",
    "        if self.attention_module:\n",
    "            self.attention_module.eval()\n",
    "        if self.senet_module:\n",
    "            self.senet_module.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            trues = []\n",
    "            bs = 0\n",
    "            for lr_grace_05, lr_grace_025, hr_aux in self.test_loader:\n",
    "                bs += 1\n",
    "                # Save predictions and true values for metrics calculation\n",
    "                lr_grace_05, lr_grace_025, hr_aux = lr_grace_05.to(self.device), lr_grace_025.to(self.device), hr_aux.to(self.device)\n",
    "                lr_grace = F.interpolate(lr_grace_05, scale_factor=0.5, mode='bicubic', align_corners=False)\n",
    "\n",
    "                # Combine lr_grace and downsampled hr_aux\n",
    "                downsampled_aux = F.interpolate(hr_aux, scale_factor=0.25, mode='bicubic', align_corners=False)\n",
    "                combined_input = torch.cat([lr_grace, downsampled_aux], dim=1)\n",
    "\n",
    "                # Learn relationship features\n",
    "                relationship_features = combined_input\n",
    "                if self.attention_module:\n",
    "                    relationship_features = self.attention_module(relationship_features)\n",
    "                elif self.senet_module:\n",
    "                    relationship_features = self.senet_module(relationship_features)\n",
    "\n",
    "                # Generate HR result using upsampling module\n",
    "                hr_generated = self.upsampling_module(relationship_features)\n",
    "\n",
    "                # Upsample lr_grace to create the ground truth for hr_generated\n",
    "                hr_grace_upsampled = lr_grace_025\n",
    "                preds.append(hr_generated.cpu().numpy())\n",
    "                trues.append(hr_grace_upsampled.cpu().numpy())\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            preds = np.concatenate(preds, axis=0).reshape(-1)\n",
    "            trues = np.concatenate(trues, axis=0).reshape(-1)\n",
    "\n",
    "            cc = np.corrcoef(trues, preds)\n",
    "            mse = mean_squared_error(trues, preds)\n",
    "            mae = mean_absolute_error(trues, preds)\n",
    "            r2 = r2_score(trues, preds)\n",
    "\n",
    "            print(f\"Test MSE: {mse}, Test MAE: {mae}, Test R²: {r2}, Test cc: {cc}\")\n",
    "\n",
    "        return preds, trues, r2\n",
    "\n",
    "# Define the EnsembleTrainer class\n",
    "class EnsembleTrainer:\n",
    "    def __init__(self, num_ensemble, model_trainer_kwargs, ensemble_dir='ensemble_models'):\n",
    "        \"\"\"\n",
    "        Initializes the EnsembleTrainer.\n",
    "        \n",
    "        Parameters:\n",
    "            num_ensemble (int): Number of ensemble members.\n",
    "            model_trainer_kwargs (dict): Keyword arguments to pass to ModelTrainer.\n",
    "            ensemble_dir (str): Directory to save ensemble models.\n",
    "        \"\"\"\n",
    "        self.num_ensemble = num_ensemble\n",
    "        self.model_trainer_kwargs = model_trainer_kwargs\n",
    "        self.ensemble_dir = ensemble_dir\n",
    "        os.makedirs(self.ensemble_dir, exist_ok=True)\n",
    "        self.seeds = [42 + i for i in range(num_ensemble)]  # Different seed for each member\n",
    "\n",
    "    def set_seed(self, seed):\n",
    "        \"\"\"Sets the random seed for reproducibility.\"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    def train_ensemble(self):\n",
    "        \"\"\"Trains each ensemble member and saves the trained models.\"\"\"\n",
    "        for i, seed in enumerate(self.seeds):\n",
    "            print(f\"\\n===== Training Ensemble Member {i+1}/{self.num_ensemble} with Seed {seed} =====\")\n",
    "            self.set_seed(seed)\n",
    "            # Update model_trainer_kwargs with the fixed 'rand' for consistent data split\n",
    "            trainer_kwargs = copy.deepcopy(self.model_trainer_kwargs)\n",
    "            trainer_kwargs['rand'] = 42  # Fixed seed for data split to ensure same train/test split across members\n",
    "            \n",
    "            # Initialize ModelTrainer\n",
    "            trainer = ModelTrainer(**trainer_kwargs)\n",
    "            \n",
    "            # Train the model\n",
    "            train_losses_G, train_losses_D = trainer.train()\n",
    "            \n",
    "            # Save the trained upsampling_module\n",
    "            model_save_path = os.path.join(self.ensemble_dir, f'best_model_member_{i+1}.pth')\n",
    "            torch.save(trainer.upsampling_module.state_dict(), model_save_path)\n",
    "            print(f\"Saved Ensemble Member {i+1} model to '{model_save_path}'\")\n",
    "\n",
    "    def load_ensemble_models(self, model_class, device, input_channels, attention_type=None):\n",
    "        \"\"\"\n",
    "        Loads all ensemble models from the ensemble directory.\n",
    "        \n",
    "        Parameters:\n",
    "            model_class (class): The class of the upsampling module.\n",
    "            device (torch.device): Device to load the models onto.\n",
    "            input_channels (int): Number of input channels for the model.\n",
    "            attention_type (str or None): Type of attention used, if any.\n",
    "        \n",
    "        Returns:\n",
    "            list: List of loaded models.\n",
    "        \"\"\"\n",
    "        models = []\n",
    "        for i in range(1, self.num_ensemble + 1):\n",
    "            model_path = os.path.join(self.ensemble_dir, f'best_model_member_{i}.pth')\n",
    "            if not os.path.exists(model_path):\n",
    "                raise FileNotFoundError(f\"Model file '{model_path}' does not exist.\")\n",
    "            model = model_class(input_channels=input_channels, attention_type=attention_type).to(device)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.eval()\n",
    "            models.append(model)\n",
    "            print(f\"Loaded Ensemble Member {i} from '{model_path}'\")\n",
    "        return models\n",
    "\n",
    "    def predict_ensemble(self, models, test_loader):\n",
    "        \"\"\"\n",
    "        Generates predictions from all ensemble members.\n",
    "        \n",
    "        Parameters:\n",
    "            models (list): List of trained models.\n",
    "            test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Array of predictions from each ensemble member. \n",
    "                        Shape: (num_ensemble, num_samples, channels, lat, lon)\n",
    "            np.ndarray: Array of ground truth values. \n",
    "                        Shape: (num_samples, channels, lat, lon)\n",
    "        \"\"\"\n",
    "        [lr_grace_05o, trend05o], [lr_grace_025o, trend25o], hr_auxo, grace_scaler_05o, grace_scaler_025o, aux_scalerso = load_data()\n",
    "        # Will store predictions from each ensemble member\n",
    "        # and the ground truths (we only need one copy of ground truth)\n",
    "        all_preds = []\n",
    "        all_trues = None  # We'll set this after the first model\n",
    "\n",
    "        # Loop over each ensemble member\n",
    "        for idx, model in enumerate(models):\n",
    "            print(f\"\\n===== Predicting with Ensemble Member {idx+1} =====\")\n",
    "            \n",
    "            # Lists to accumulate batch-wise predictions and ground truths for this model\n",
    "            preds_per_model = []\n",
    "            trues_per_model = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Loop over batches in the test_loader\n",
    "                for lr_grace_05, lr_grace_025, hr_aux in test_loader:\n",
    "                    # Prepare inputs\n",
    "                    lr_grace = F.interpolate(lr_grace_05, scale_factor=0.5, mode='bicubic', align_corners=False)\n",
    "                    lr_grace = lr_grace.to(model.device)\n",
    "                    hr_aux = hr_aux.to(model.device)\n",
    "                    lr_grace_025 = lr_grace_025.to(model.device)\n",
    "\n",
    "                    # Combine lr_grace and downsampled hr_aux\n",
    "                    downsampled_aux = F.interpolate(hr_aux, scale_factor=0.25, mode='bicubic', align_corners=False)\n",
    "                    combined_input = torch.cat([lr_grace, downsampled_aux], dim=1)\n",
    "\n",
    "                    # Generate HR result using the upsampling module\n",
    "                    hr_generated = model(combined_input)\n",
    "\n",
    "                    # Collect predictions and ground truth for this batch\n",
    "                    preds_per_model.append(hr_generated.cpu().numpy())\n",
    "                    trues_per_model.append(lr_grace_025.cpu().numpy())\n",
    "\n",
    "            # Concatenate all batches for this ensemble member\n",
    "            preds_per_model = np.concatenate(preds_per_model, axis=0)  # (num_samples, channels, lat, lon)\n",
    "            trues_per_model = np.concatenate(trues_per_model, axis=0)  # (num_samples, channels, lat, lon)\n",
    "            preds_per_model = grace_scaler_05o.inverse_transform(preds_per_model.reshape(-1, 1)).reshape(preds_per_model.shape)\n",
    "            trues_per_model = grace_scaler_05o.inverse_transform(trues_per_model.reshape(-1, 1)).reshape(trues_per_model.shape)\n",
    "            print(f\"Ensemble Member {idx+1} Predictions Shape: {preds_per_model.shape}\")\n",
    "\n",
    "            # Store the predictions\n",
    "            all_preds.append(preds_per_model)\n",
    "\n",
    "            # For ground truth, we only need to store it once\n",
    "            # (assuming the ground truth doesn't change between ensemble members)\n",
    "            if idx == 0:\n",
    "                all_trues = trues_per_model\n",
    "\n",
    "        # Stack all ensemble predictions into shape: (num_ensemble, num_samples, channels, lat, lon)\n",
    "        all_preds = np.stack(all_preds, axis=0)\n",
    "        \n",
    "        print(f\"\\nAll Ensemble Predictions Shape: {all_preds.shape}\")\n",
    "        print(f\"Ground Truths Shape: {all_trues.shape}\")\n",
    "        \n",
    "        return all_preds, all_trues\n",
    "\n",
    "    def compute_uncertainty(self, all_preds, trues):\n",
    "        \"\"\"\n",
    "        Computes the mean and standard deviation across ensemble predictions.\n",
    "        \n",
    "        Parameters:\n",
    "            all_preds (np.ndarray): Predictions from all ensemble members. Shape: (num_ensemble, num_samples, channels, lat, lon)\n",
    "            trues (np.ndarray): Ground truth values. Shape: (num_samples, channels, lat, lon)\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Mean predictions across ensemble members.\n",
    "            np.ndarray: Uncertainty estimates (standard deviation) across ensemble members.\n",
    "            float: R² score for the ensemble mean.\n",
    "        \"\"\"\n",
    "        tpbh = np.load('tpb_h.npy')\n",
    "        mask = tpbh == 0  # Assuming mask shape is (lat, lon)       \n",
    "        # Apply spatial mask to predictions\n",
    "        all_preds_masked = all_preds.copy()\n",
    "        all_preds_masked[:, :, :, mask] = np.nan\n",
    "        \n",
    "        # Apply spatial mask to ground truth\n",
    "        trues_masked = trues.copy()\n",
    "        trues_masked[:, :, mask] = np.nan\n",
    "        \n",
    "        # Compute spatial means (over lat/lon) for predictions and truth\n",
    "        preds_ts = np.nanmean(all_preds_masked, axis=(3, 4))  # Shape: (5, T, C)\n",
    "        trues_ts = np.nanmean(trues_masked, axis=(2, 3))      # Shape: (T, C)\n",
    "        \n",
    "        # Compute ensemble statistics\n",
    "        mean_preds = np.nanmean(preds_ts, axis=0)  # Shape: (T, C)\n",
    "        std_preds = np.nanstd(preds_ts, axis=0)    # Shape: (T, C)\n",
    "        \n",
    "        # Prepare R² calculation with aligned non-NaN values\n",
    "        valid_mask = ~np.isnan(trues_ts) & ~np.isnan(mean_preds)\n",
    "        trues_valid = trues_ts[valid_mask].flatten()\n",
    "        preds_valid = mean_preds[valid_mask].flatten()\n",
    "        \n",
    "        r2 = r2_score(trues_valid, preds_valid)\n",
    "        \n",
    "        return mean_preds, std_preds, r2\n",
    "\n",
    "    def save_uncertainty(self, std_preds, save_path='ensemble_uncertainty.npy'):\n",
    "        \"\"\"Saves the uncertainty estimates to a .npy file.\"\"\"\n",
    "        np.save(save_path, std_preds)\n",
    "        print(f\"Saved uncertainty estimates to '{save_path}'\")\n",
    "\n",
    "    def save_mean_predictions(self, mean_preds, save_path='ensemble_mean_predictions.npy'):\n",
    "        \"\"\"Saves the mean predictions to a .npy file.\"\"\"\n",
    "        np.save(save_path, mean_preds)\n",
    "        print(f\"Saved mean predictions to '{save_path}'\")\n",
    "\n",
    "def visualize_uncertainty(std_preds, sample_indices=[0], channel=0):\n",
    "    \"\"\"\n",
    "    Visualizes the uncertainty maps for specified samples.\n",
    "    \n",
    "    Parameters:\n",
    "        std_preds (np.ndarray): Uncertainty estimates. Shape: (num_samples, channels, lat, lon)\n",
    "        sample_indices (list): List of sample indices to visualize.\n",
    "        channel (int): Channel index to visualize (default is 0).\n",
    "    \"\"\"\n",
    "    for idx in sample_indices:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(std_preds[idx, channel], cmap='viridis')\n",
    "        plt.colorbar(label='Uncertainty (Std Dev)')\n",
    "        plt.title(f'Uncertainty Map for Sample {idx}')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # Number of ensemble members\n",
    "    num_ensemble = 5  # You can adjust this number as needed\n",
    "\n",
    "    # Load data (this is where your downscaled data is loaded)\n",
    "    [lr_grace_05, trend05], [lr_grace_025, trend25], hr_aux, grace_scaler_05, grace_scaler_025, aux_scalers = load_data_with_augmentation()\n",
    "\n",
    "    # Initialize model_trainer_kwargs\n",
    "    model_trainer_kwargs = {\n",
    "        'epochs': 100,\n",
    "        'batch_size': 16,\n",
    "        'relationship_learner': None,\n",
    "        'relationship_output_channels': 64,\n",
    "        'smoothing_method': None,\n",
    "        'attention': None,\n",
    "        'senet': None\n",
    "    }\n",
    "\n",
    "    # Initialize EnsembleTrainer\n",
    "    ensemble_trainer = EnsembleTrainer(num_ensemble=num_ensemble, \n",
    "                                       model_trainer_kwargs=model_trainer_kwargs, \n",
    "                                       ensemble_dir='ensemble_models')\n",
    "\n",
    "    # Train ensemble models\n",
    "    ensemble_trainer.train_ensemble()\n",
    "\n",
    "    # Load ensemble models\n",
    "    models = ensemble_trainer.load_ensemble_models(\n",
    "        model_class=FlexibleUpsamplingModule, \n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'), \n",
    "        input_channels=hr_aux.shape[-1] + 1,  \n",
    "        attention_type=None\n",
    "    )\n",
    "\n",
    "    # Initialize ModelTrainer (this will give access to the full data for prediction)\n",
    "    temp_trainer_kwargs = copy.deepcopy(model_trainer_kwargs)\n",
    "    temp_trainer_kwargs['rand'] = 42  # Fixed seed for data split\n",
    "    temp_trainer_kwargs['epochs'] = 0  # No training, just to load the data\n",
    "    temp_trainer = ModelTrainer(**temp_trainer_kwargs)\n",
    "\n",
    "    # You can predict on the full dataset, not just the test set\n",
    "    full_loader = temp_trainer.full_loader  # Ensure 'full_loader' gives access to the entire dataset\n",
    "\n",
    "    # Perform ensemble predictions for the full dataset\n",
    "    all_preds, trues = ensemble_trainer.predict_ensemble(models, full_loader)\n",
    "\n",
    "    # Compute uncertainty across the entire dataset\n",
    "    mean_preds, std_preds, r2 = ensemble_trainer.compute_uncertainty(all_preds, trues)\n",
    "\n",
    "    # Save uncertainty estimates\n",
    "    ensemble_trainer.save_mean_predictions(mean_preds, save_path='ensemble_mean_predictions.npy')\n",
    "    ensemble_trainer.save_uncertainty(std_preds, save_path='ensemble_uncertainty_averaged.npy')\n",
    "\n",
    "    # Save full dataset ground truths and mean predictions\n",
    "    np.save('ensemble_trues.npy', trues)\n",
    "    np.save('ensemble_mean_preds.npy', mean_preds)\n",
    "\n",
    "    # Visualize uncertainty for selected samples\n",
    "    #visualize_uncertainty(std_preds, sample_indices=[0, 10, 20], channel=0)\n",
    "\n",
    "    # Print R² score for full dataset\n",
    "    print(f\"Ensemble Mean R² Score (Full Dataset): {r2}\")\n",
    "\n",
    "    # Save the full uncertainty map (now with the same shape as your downscaled data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_uncertainty(std_preds, sample_indices=[0], channel=0, rotate=False):\n",
    "    \"\"\"\n",
    "    Visualizes the uncertainty maps for specified samples.\n",
    "    \n",
    "    Parameters:\n",
    "        std_preds (np.ndarray): Uncertainty estimates. Shape: (num_samples, channels, lat, lon)\n",
    "        sample_indices (list): List of sample indices to visualize.\n",
    "        channel (int): Channel index to visualize (default is 0).\n",
    "        rotate (bool): Whether to rotate the uncertainty map by 90 degrees anti-clockwise.\n",
    "    \"\"\"\n",
    "    for idx in sample_indices:\n",
    "        data = std_preds[idx, channel]\n",
    "        if rotate:\n",
    "            data = np.rot90(data)  # Rotate 90 degrees anti-clockwise\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))  # Keep figure size constant\n",
    "        plt.imshow(data, cmap='viridis', aspect='auto')  # Ensure correct aspect ratio\n",
    "        plt.colorbar(label='Uncertainty (Std Dev)', pad=0.01)\n",
    "        plt.title(f'Uncertainty Map for Sample {idx}', pad=10)\n",
    "        plt.xlabel('Longitude', labelpad=5)\n",
    "        plt.ylabel('Latitude', labelpad=5)\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.tight_layout()  # Adjust layout for better spacing\n",
    "        plt.show()\n",
    "unc=np.load('ensemble_uncertainty.npy')\n",
    "print(np.shape(unc))\n",
    "mee=np.nanmean(unc)\n",
    "print(mee)\n",
    "\n",
    "tpbh=np.load('tpb_h.npy')\n",
    "unc[:,:,tpbh==0]=np.nan\n",
    "visualize_uncertainty(unc, sample_indices=[0, 10, 20], channel=0, rotate=True)  # Adjust sample_indices as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
